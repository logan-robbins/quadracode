\documentclass[11pt, a4paper]{article}

% --- CONSOLIDATED PREAMBLE ---
% Geometry and layout
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}

% Typography and Fonts
% Use standard T1 encoding and Computer Modern fonts (arXiv default)
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc} % Handle UTF-8 input
\usepackage[english]{babel} % For typography rules and quotes

% Math packages
\usepackage{amsmath}
\usepackage{amssymb}

% Utility packages
\usepackage{booktabs}   % For professional tables (from related_work.tex)
\usepackage{graphicx}   % For images (from related_work.tex)
\usepackage{xcolor}     % For colors (from related_work.tex)
\usepackage[hidelinks]{hyperref} % For hyperlinks (loaded last)

% --- TITLE AND AUTHOR ---
\title{Quadracode: A Persistent Orchestration Runtime for Long‑Horizon AI Agents with Skeptical Gating and Deterministic Replay}
\author{
    Logan Robbins \\
    Independent Researcher \\
    \texttt{ljrweb@gmail.com}
}


\begin{document}
\maketitle


\section*{Abstract}
\label{sec:abstract}
We introduce \textbf{Quadracode}, an orchestration runtime for resilient, long-horizon autonomous agents that emphasizes System-2--style self-reflection, fault tolerance, and continuous operation. Quadracode addresses a common failure mode---premature termination under ambiguity or apparent completion---by coupling a hierarchical manager--worker design with a protocol-level skeptical gate (a stateless HumanClone reviewer) and a two-level autonomy loop that alternates $\text{Evaluate} \to \text{Critique} \to \text{Plan} \to \text{Execute}$ and $\text{Propose} \to \text{Reject} \to \text{Refine}$ until success or a fail-safe halt with operator escalation.. To sustain long-horizon work, Quadracode implements a \textbf{Perpetual Refinement Protocol (PRP)} with a checkpointed refinement ledger for durable state, service-residency (\textquotedblleft hotpath\textquotedblright) controls to prevent agent decay, and deterministic replay for time-travel debugging and causal analysis. Together, these mechanisms deliver false-stop detection, robust recovery from agent or infrastructure faults, and auditable execution traces suitable for real deployments.

\section{Introduction}
Long-horizon autonomy remains brittle. Contemporary language-model agents often stop too early---declaring success after a plausible intermediate artifact or when confronted with ambiguity, partial failure, or shifting goals (cf. \cite{Wang2023}). This \textquotedblleft false-stop\textquotedblright\ mode is amplified by prompt-level conventions (\textquotedblleft ask yourself if you’re done\textquotedblright) that an agent can ignore when under uncertainty (e.g., \cite{Huang2023}) or when local reward signals are misleading. For real deployments---software operations, data maintenance, multi-step analysis---what matters is not just accuracy per step but the ability to keep working safely, to recover from faults, and to surface an auditable trace when progress stalls.

We take a systems view of this problem. Rather than relying on ad-hoc prompting or per-agent heuristics, we institutionalize \textquotedblleft keep-going\textquotedblright\ as a protocol-level invariant.

\subsection{From prompt conventions to protocol invariants}
Our design is motivated by three observations about deployed agent systems:

Prompt-level self-reflection is fragile. Declarative instructions (\textquotedblleft reflect, verify, then proceed\textquotedblright) do not guarantee conformance under uncertainty, distribution shift, or tool failures (e.g., \cite{Huang2023}).

Persistence requires engineered residency. Long-lived services that are frequently scaled to zero or reaped by orchestration layers decay (lose context, caches, and tool bindings), a classic challenge in stateful distributed systems \cite{Sreekanti2022}.

Reliability requires causal observability. When runs fail or stall, operators need more than logs; they need deterministic replay to reconstruct state transitions and perform causal analysis (a challenge addressed by recent agent debugging frameworks \cite{Yin2024}).

Quadracode therefore elevates three mechanisms to protocol status:

A skeptical gate (HumanClone) that must challenge any \textquotedblleft done\textquotedblright\ proposal before acceptance.

A Perpetual Refinement Protocol (PRP) with a checkpointed refinement ledger that persists the working state across iterations and enables time-travel across checkpoints.

Service-residency (\textquotedblleft hotpath\textquotedblright) controls that keep designated agents alive and warm, preventing decay and reducing re-spin latency.

Together with deterministic replay for time-travel debugging and causal analysis, these mechanisms convert best-practice heuristics into runtime-enforced safety and liveness properties.

\subsection{A systems runtime for exhaustion-resistant autonomy}
Quadracode is a hierarchical orchestration runtime: an orchestrator manages a dynamic fleet of specialized agents (a design pattern seen in frameworks like \cite{Wu2023}) and a stateless HumanClone reviewer. The orchestrator coordinates work over an asynchronous event fabric, maintains an agent registry with residency flags, and records all PRP transitions into a ledger that supports deterministic replay. The HumanClone is intentionally simple and stateless: its only job is to challenge the orchestrator’s \textquotedblleft done\textquotedblright\ proposal and to demand refinement when evidence is insufficient. This division of responsibilities makes the skeptical check inescapable, independent of any single agent’s prompting style or transient context.

Crucially, all four pillars are implemented in our stack today:

Skeptical gate (HumanClone) as a protocol-enforced reviewer.

PRP + refinement ledger providing durable state across iterations.

Service residency (\textquotedblleft hotpath\textquotedblright) to prevent agent decay and ensure responsiveness.

Deterministic replay enabling time-travel debugging and causal attribution.

These mechanisms allow Quadracode to (i) detect and mitigate false stops, (ii) recover from agent or infrastructure faults, and (iii) produce auditable execution traces suitable for operational environments.

\subsection{Scope and non-goals}
Quadracode is not a new planner, training recipe, or model. We purposely avoid adding reinforcement learning or learned verifiers in this initial report. Our thesis is that systems invariants---skeptical gating, persistent state, residency, and replay---provide immediate, practical gains for long-horizon reliability. Learned critics, process reward models (e.g., \cite{Lightman2023}), or RL fine-tuning are promising extensions; they can be layered into the reviewer role in future work without changing the protocol.

\subsection{Contributions}
This paper makes the following contributions:

Protocol-level skepticism and persistence. We formalize and implement a two-level autonomy loop with a skeptical gate (HumanClone) and a Perpetual Refinement Protocol that together make \textquotedblleft keep going\textquotedblright\ a systems invariant rather than a prompt convention.

A production-oriented orchestration runtime. We present a hierarchical runtime with service residency and deterministic replay, yielding auditable, reproducible runs and rapid fault diagnosis.


Implementation alignment. We document how each mechanism is realized in the current codebase (orchestrator, agent registry, event fabric, refinement ledger, replay), enabling reproducibility and adoption.

\subsection{Empirical preview and paper organization}
We report two stress tests that reflect common long-horizon failure modes: (A) premature-halt resistance on a multi-step workflow where naive agents tend to stop early, and (B) failure-recovery liveness under injected faults (agent crash or short fabric outage). For each, we measure success rate, iterations to completion, recovery time, and traceability, and we provide ablations over HumanClone, PRP thresholds, residency, and replay. We also include a minimal baseline using a contemporary multi-agent framework to contextualize overheads and benefits.

The remainder of the paper proceeds as follows. \S 2 presents the system model and protocol. \S 3 details the implementation (orchestrator, registry, event fabric, PRP ledger, replay). \S 4 reports the evaluation and ablation findings. \S 5 discusses limitations and extensions (e.g., learned verifiers/RL, interoperability). \S 6 concludes.


\section{Related Work}
\label{sec:related_work}

The development of Quadracode is informed by three principal streams of recent AI research: (1) agent self-reflection and iterative refinement, (2) multi-agent orchestration frameworks, and (3) the overarching challenge of long-horizon task completion.

\subsection{Agent Reflection and Iterative Refinement}
A significant body of work has focused on moving agents beyond simple, single-pass generation. The concept of System-2--style deliberation has been explored through various prompt-based strategies. Foundational work such as \textbf{Reflexion} \cite{Shinn2023} demonstrated that agents could achieve a form of verbal reinforcement learning by critiquing their past actions and storing those reflections in memory to improve subsequent trials. Similarly, \textbf{Self-Refine} \cite{Madaan2023} introduced an iterative loop where an LLM acts as its own generator, critic, and refiner to improve output quality without external feedback.

This concept of iterative deliberation was further structured by search algorithms, most notably in \textbf{Tree of Thoughts (ToT)} \cite{Yao2023}, which enables an agent to explore multiple reasoning paths, evaluate them, and backtrack, creating a more robust problem-solving process.

While powerful, these approaches primarily address the \textit{reasoning} or \textit{prompting} layer of autonomy. They are often implemented as in-memory loops and are not intrinsically designed to handle systemic failures, such as infrastructure interruptions, agent process crashes, or the need for durable state persistence over multi-day operations. Quadracode builds on these reflective and iterative concepts (e.g., our two-level autonomy loop) but embeds them within a robust \textit{systems runtime} that prioritizes fault tolerance and durability, which we identify as a critical missing piece for real-world deployment.

\subsection{Multi-Agent Orchestration}
The complexity of modern tasks has driven a shift from single-agent solutions to coordinated, multi-agent systems. Recent frameworks like \textbf{AutoGen} \cite{Wu2023} have popularized this approach, enabling complex tasks by orchestrating conversations between multiple specialized agents (e.g., a "writer" and a "coder"). These systems demonstrate how a hierarchical or collaborative decomposition---similar to Quadracode's manager--worker design---can solve problems that are intractable for a single agent.

However, these frameworks often focus on the \textit{collaboration protocol} and task decomposition, relying on a stable underlying environment. Quadracode's contribution is complementary; it provides the resilient, persistent orchestration \textit{fabric} required to run such multi-agent systems reliably. Our focus is less on the agent conversation patterns and more on the systemic guarantees: ensuring that if a "worker" agent fails, its state is not lost, and the "manager" can resume the operation seamlessly.

\subsection{Long-Horizon Task Resilience}
The challenge of building "exhaustion-resistant" autonomous systems is a key theme in recent agent surveys \cite{Xi2023, Wang2023}. Premature termination, context decay, and sensitivity to transient errors are recognized as major blockers to long-horizon task completion. Quadracode directly addresses this gap from a systems engineering perspective. While other work focuses on improving the \textit{context length} or \textit{reasoning quality} of the LLM itself, Quadracode provides the runtime architecture to sustain operation \textit{despite} the inherent limitations of today's models. Our Perpetual Refinement Protocol (PRP), checkpointed ledger, and service-residency controls are all novel mechanisms designed specifically to deliver the systems-level resilience required for true, long-horizon autonomy.


\section{System Model \& Problem Setting}
\label{sec:system_model}

This section formalizes the setting Quadracode targets and the system model we assume. Our aim is to make \textquotedblleft keep going\textquotedblright\ a \textbf{runtime contract}---not a prompt convention---under the realities of long-horizon, tool-using agents that must withstand ambiguity, partial failures, and platform churn.

\subsection{Task Scope and Goals}

We focus on multi-step workflows where naïve agents often \textbf{stop too early} (false-stops) or drift after context loss. The system must (i) sustain progress across many iterations, (ii) recover from agent/tool/fabric faults without human babysitting, and (iii) leave an \textbf{auditable, replayable} trace suitable for incident analysis and reproducibility. These goals motivate protocol-level skepticism before acceptance, durable state across iterations, \textbf{service residency} to prevent agent decay, and \textbf{deterministic replay} for causal debugging.

\subsection{Actors and Roles}
\begin{itemize}
    \item \textbf{Orchestrator.} The executive agent that decomposes goals, allocates work, tracks budgets, governs the refinement loop, and proposes completion.
    \item \textbf{Agent Fleet.} Specialized worker agents spawned and retired dynamically by the orchestrator to execute concrete sub-tasks.
    \item \textbf{HumanClone (skeptical gate).} A \textbf{stateless reviewer} (a pattern related to LLM-as-a-judge \cite{Zheng2023}) whose sole purpose is to \textbf{challenge any \textquotedblleft done\textquotedblright\ proposal} and force refinement when evidence is insufficient; this makes the final check \textbf{inescapable}.
    \item \textbf{Operator.} A human who may receive a fail-safe escalation bundle (ledger + replay trace) when bounded-improvement criteria are not met.
\end{itemize}
These roles are first-class in the implementation via distinct profiles, prompts, and graph nodes in the runtime.

\subsection{System Assumptions}
\begin{itemize}
    \item \textbf{Tool access \& async fabric.} Agents invoke tools and coordinate over an \textbf{event fabric} backed by Redis Streams; messages conform to a canonical \textbf{MessageEnvelope} schema. The messaging layer is exposed as tools (MCP-style), enabling testing/mocking and backend substitution without code changes.
    \item \textbf{Central runtime state.} A single \textbf{QuadraCodeState} object tracks PRP status, exhaustion signals, context/memory slices, telemetry, invariants, and autonomy counters; (de)serialization routines persist/restore this state for logging and replay.
    \item \textbf{No training requirement (v1).} The system does not require custom model training; an optional \textbf{exhaustion predictor} learns simple heuristics online from the refinement ledger to pre-empt unproductive loops.
\end{itemize}

\subsection{Failure \& Threat Model}

We design for the following classes of failure, all observable and actionable via the protocol:

\begin{enumerate}
    \item \textbf{Agent-level failures.} Hallucinated conclusions, \textbf{premature \textquotedblleft done\textquotedblright} proposals, tool exceptions/backpressure, or \textbf{context saturation} that degrades reasoning (e.g., \cite{Liu2023}). These manifest as \textbf{exhaustion modes} that gate PRP transitions.
    \item \textbf{Orchestration/fabric faults.} Process crashes or transient messaging outages; we require \textbf{idempotent envelopes}, append-only logging, and \textbf{deterministic replay} to reconstruct causality and resume work.
    \item \textbf{Platform-level churn (agent decay).} Autoscaling or lifecycle events that evict agents and destroy warm context; we therefore enforce \textbf{service residency (\textquotedblleft hotpath\textquotedblright)} to protect designated agents from teardown and to make deletion contingent on registry checks.
\end{enumerate}

Adversarial threats (e.g., malicious tools) are \textbf{out of scope} for v1 but the message schema and workspace integrity checks provide a foundation for future hardening.

\subsection{Design Objectives and Properties}

To meet these conditions, Quadracode elevates four mechanisms from heuristics to \textbf{protocol invariants}:

\begin{itemize}
    \item \textbf{Skeptical gate (HumanClone).} No acceptance without at least one independent challenge \textbf{after} the last state-changing action; the gate is enforced by a dedicated trigger path that resets the loop for refinement. \textbf{Property — Safety:} prevents silent success on stale evidence.
    \item \textbf{Perpetual Refinement Protocol (PRP).} A guarded finite state machine with explicit states \texttt{{HYPOTHESIZE, EXECUTE, TEST, CONCLUDE, PROPOSE}}, \textbf{transition validators}, and \textbf{ledgered checkpoints} across cycles. \textbf{Property — Traceability:} every transition appends to a structured record for audit.
    \item \textbf{Service residency (\textquotedblleft hotpath\textquotedblright).} Registry-mediated residency flags block deletion of protected agents and keep them warm; this reduces re-spin latency and \textbf{prevents decay} during long runs. \textbf{Property — Persistence.}
    \item \textbf{Deterministic replay.} An append-only \textbf{time-travel recorder} writes stage transitions, tool calls, and snapshots as JSONL; CLI tools support \textbf{replay} and \textbf{diff}, enabling incident forensics and causal attribution. \textbf{Property — Recoverability \& Auditability.}
\end{itemize}

Finally, a lightweight \textbf{invariants module} enforces run-time checks (e.g., \textquotedblleft test-after-rejection,\textquotedblright\ \textquotedblleft context-updated-per-cycle,\textquotedblright\ \textquotedblleft skepticism-gate-satisfied\textquotedblright), logging violations and \textbf{blocking} unsafe transitions to PROPOSE/CONCLUDE. This makes the liveness/safety contract explicit and machine-checkable during long-horizon operation.

Quadracode assumes tool-using agents on an async fabric with durable state and observability. Within this model, \textbf{false-stop resistance}, \textbf{residency-backed persistence}, and \textbf{replay-backed recovery} are not best-effort behaviors but \textbf{enforced protocol properties}, providing a practical foundation for exhaustion-resistant autonomy.


\section{Protocol: Skeptical Gating and Perpetual Refinement (PRP)}
\label{sec:protocol}
This section specifies the protocol that makes \textquotedblleft keep going\textquotedblright\ a runtime invariant: a two-level autonomy loop enforced by a guarded state machine, a checkpointed refinement ledger, and a mandatory skeptical review prior to acceptance. The protocol is realized in the runtime as explicit types, validated transitions, and a trigger path that is inescapable once the orchestrator proposes \textquotedblleft done.\textquotedblright

\subsection{Two-Level Autonomy Loop}
\begin{itemize}
    \item \textbf{Inner loop (orchestrator $\leftrightarrow$ agents).} The orchestrator iterates $\text{Evaluate} \to \text{Critique} \to \text{Plan} \to \text{Execute}$, delegating concrete steps to worker agents and updating state after each cycle. This loop can run indefinitely subject to budget and improvement criteria.
    \item \textbf{Outer loop (orchestrator $\leftrightarrow$ HumanClone).} When the orchestrator believes the task is complete, it must invoke a skeptical gate---the stateless HumanClone reviewer. HumanClone responds with a structured trigger that, unless acceptance is justified, forces a return to hypothesis and further refinement ($\text{Propose} \to \text{Reject} \to \text{Refine}$). This makes a final review protocol-level, not prompt-level.
    \item \textbf{Enforcement mechanism.} The outer loop is enforced by the \texttt{prp\_trigger\_check} node: upon receiving a HumanClone message, the node parses the \texttt{HumanCloneTrigger} payload, updates the runtime’s \texttt{exhaustion\_mode} and \texttt{requirements}, and applies a PRP transition back to \texttt{HYPOTHESIZE}. The orchestrator cannot bypass this path.
    \item \textbf{Termination policy.} If bounded improvement is not observed within budget, the run performs a fail-safe halt with operator escalation, emitting an auditable bundle (refinement ledger + replay trace).
\end{itemize}

\subsection{PRP State Machine (Formalization)}
\begin{itemize}
    \item \textbf{States.} \texttt{HYPOTHESIZE}, \texttt{EXECUTE}, \texttt{TEST}, \texttt{CONCLUDE}, \texttt{PROPOSE}.
    \item \textbf{Transitions and guards.} Transitions are stored as a directed graph with guarded edges. Guard types include:
    \begin{itemize}
        \item \texttt{allow\_if\_exhaustion\_in} / \texttt{block\_if\_exhaustion\_in}: gate on current \texttt{ExhaustionMode};
        \item \texttt{requires\_human\_clone}: require a prior HumanClone trigger for the edge.
    \end{itemize}
    Examples (default graph): \texttt{TEST}$\to$\texttt{CONCLUDE} is blocked on \texttt{TEST\_FAILURE}; \texttt{PROPOSE}$\to$\texttt{HYPOTHESIZE} requires \texttt{human\_clone\_triggered=True}. Invalid edges raise \texttt{PRPInvalidTransitionError}.
    \item \textbf{Ledgered checkpoints.} Each cycle appends a \texttt{RefinementLedgerEntry} (hypothesis, status, outcome, metrics), enabling deterministic replay and post-hoc analysis.
    \item \textbf{Trigger contract.} HumanClone’s response is a typed payload (\texttt{HumanCloneTrigger}) containing the cycle index, an exhaustion mode, required artifacts, and rationale; this schema underpins reliable enforcement of the reject-and-refine step.
\end{itemize}

\subsection{Protocol Invariants and Properties}
\begin{itemize}
    \item \textbf{Safety (post-action challenge).} No completion is accepted unless a HumanClone challenge occurs \textit{after} the last state-changing action; \texttt{PROPOSE}$\to$\texttt{HYPOTHESIZE} is therefore gated by \texttt{requires\_human\_clone}. This prevents \textquotedblleft silent success\textquotedblright\ on stale evidence.
    \item \textbf{Liveness (budget-bounded progress).} If improvement stalls as defined by novelty thresholds (0.15) and exhaustion prediction (0.7), the protocol halts safely and escalates, rather than looping without bound. Telemetry increments false-stop counters for operator visibility.
    \item \textbf{Traceability (append-only ledger).} Every PRP transition and tool call is appended to a time-travel log and refinement ledger; the recorder and CLI provide replay and diff for causal attribution.
    \item \textbf{Persistence (residency).} Residency flags and registry checks ensure designated \textquotedblleft hotpath\textquotedblright\ agents persist across long runs and are protected from deletion, avoiding context decay during PRP.
\end{itemize}

An invariants module maintains machine-checkable flags (e.g., \texttt{skepticism\_gate\_satisfied}, \texttt{needs\_test\_after\_rejection}, \texttt{context\_updated\_in\_cycle}) and blocks unsafe transitions, logging violations to the ledger.

\subsection{Progress Signals, Budgeting, and Escalation}
\begin{itemize}
    \item \textbf{Improvement signals.} The runtime monitors: (i) task-level metrics logged per ledger entry, (ii) context quality/usage, (iii) exhaustion probability/mode, and (iv) novelty thresholds that guard against self-repetition. These signals determine whether to continue or to adjust hypotheses.
    \item \textbf{Budgeting.} Budgets (iterations, tokens/cost, wall-clock) are tracked by the orchestrator; transitions that would violate budgets are blocked and routed to escalation. Selected transitions are also gated on resource states (e.g., backpressure), as in the default graph’s \texttt{EXECUTE}$\to$\texttt{HYPOTHESIZE} on predicted exhaustion.
    \item \textbf{Escalation condition.} If no measurable improvement beyond $\epsilon$ is observed over $B$ cycles---or if a hard budget limit is reached---the protocol emits an incident bundle (ledger + replay snapshot + workspace manifest) and performs a fail-safe halt with operator notification.
\end{itemize}

\subsection{Algorithm Sketch (PRP Control Loop)}

\begin{quote}
\texttt{Initialize state $\leftarrow$ make\_initial\_context\_engine\_state()}\\
\texttt{repeat}\\
\texttt{\ \ // Inner loop}\\
\texttt{\ \ HYPOTHESIZE: update hypothesis; log\_stage("hypothesize")}\\
\texttt{\ \ EXECUTE: delegate to agents; log\_tool(...); update state}\\
\texttt{\ \ TEST: evaluate artifacts; log\_stage("test")}\\
\texttt{\ \ if tests indicate success then}\\
\texttt{\ \ \ \ CONCLUDE: prepare proposal; log\_stage("conclude")}\\
\texttt{\ \ \ \ PROPOSE: request\_final\_review $\to$ HumanClone}\\
\texttt{\ \ \ \ if HumanCloneTrigger received then}\\
\texttt{\ \ \ \ \ \ apply\_prp\_transition(PROPOSE $\to$ HYPOTHESIZE); update exhaustion\_mode, required\_artifacts}\\
\texttt{\ \ \ \ \ \ continue \ // reject \& refine}\\
\texttt{\ \ \ \ else}\\
\texttt{\ \ \ \ \ \ accept result; break \ // safety: only after post-action challenge}\\
\texttt{\ \ else}\\
\texttt{\ \ \ \ apply guarded transition per DEFAULT\_PRP\_TRANSITIONS}\\
\texttt{\ \ // Progress \& budget checks}\\
\texttt{\ \ if not improved\_by($\epsilon$) over last B cycles or budget\_exhausted() then}\\
\texttt{\ \ \ \ emit\_incident\_bundle(ledger, replay\_trace, workspace\_snapshot); fail\_safe\_halt\_and\_escalate()}\\
\texttt{until halted}
\end{quote}

The loop itself is data-driven: transitions are validated by \texttt{PRPStateMachine.validate\_transition(...)}, with guards referencing the current \texttt{exhaustion\_mode} and whether a HumanClone trigger occurred; every stage/transition/tool call is appended to the recorder and ledger for replay.

\textit{Implementation note.} Messages traverse the Redis-Streams event fabric via a canonical \texttt{MessageEnvelope}, enabling idempotent, durable communication between orchestrator, agents, registry, and HumanClone. This provides the append-only substrate assumed by PRP. Improvement threshold $\epsilon$ and budget $B$ are implicitly enforced via novelty scoring (threshold 0.15), exhaustion prediction (threshold 0.7), and test enforcement, rather than explicit parameters.


\section{Implementation}
\label{sec:implementation}
This section maps the protocol and architecture to concrete code paths and data contracts. The emphasis is on what is implemented now, with enough specificity for reproduction and code review.

\subsection{Runtime and Messaging Contracts}
Quadracode’s event fabric is implemented on Redis Streams behind a thin \textquotedblleft MCP-style\textquotedblright\ abstraction. All inter-component messages conform to a canonical \texttt{MessageEnvelope} (timestamp, sender, recipient, message, payload), with mailbox keys standardized as \texttt{qc:mailbox/<recipient\_id>}. Serialization/deserialization handles poison pills (malformed JSON) safely. The \texttt{RedisMCPMessaging} adapter wraps \texttt{xadd}/\texttt{xrange}/\texttt{xdel} and exposes them as tools, enabling test/mocking and backend substitution without changing calling code. Durable append-only semantics on the stream provide a natural audit trail.

\subsection{State Management}
A single \texttt{QuadraCodeState} \texttt{TypedDict} is the source of truth for the LangGraph program. It tracks PRP status and cycles; exhaustion signals; context usage and quality; memory slices; observability (time-travel log, PRP telemetry, metrics); protocol invariants; and autonomy counters (false-stops and challenges). For performance, the top-level is a \texttt{TypedDict} while nested structures (e.g., the ledger) use Pydantic. JSON-safe (de)serialization routines convert models, enums, and datetimes, and coerce fields on restore; an initializer creates a fully populated default state.

\subsection{Perpetual Refinement Protocol (PRP) Engine}
The PRP is a formal finite-state machine with states \{\texttt{HYPOTHESIZE}, \texttt{EXECUTE}, \texttt{TEST}, \texttt{CONCLUDE}, \texttt{PROPOSE}\}. Transitions are represented as guarded edges; guards can allow/block based on the current \texttt{exhaustion\_mode} and whether a HumanClone challenge has occurred (\texttt{requires\_human\_clone}). The \texttt{PRPStateMachine} validates and applies transitions and raises a typed error on violation.

\subsection{Skeptical Gate: HumanClone Trigger Path}
The HumanClone prompt is deliberately stateless and \textquotedblleft relentlessly skeptical.\textquotedblright\ It must return a fenced JSON payload matching the \texttt{HumanCloneTrigger} schema (cycle index, exhaustion mode, required artifacts, rationale). Incoming HumanClone messages are intercepted by the \texttt{prp\_trigger\_check} node: the trigger is parsed, \texttt{exhaustion\_mode} and \texttt{requirements} are written into state, and the PRP is forced back to \texttt{HYPOTHESIZE}, transforming the message into a structured critique record and capturing a workspace snapshot. This is the enforcement point for $\text{Propose} \to \text{Reject} \to \text{Refine}$.

\subsection{Protocol Invariants}
Protocol compliance is machine-checked via an invariants block in state (e.g., \texttt{skepticism\_gate\_satisfied}, \texttt{needs\_test\_after\_rejection}, \texttt{context\_updated\_in\_cycle}, \texttt{novelty\_threshold}), with violations logged and transitions blocked. This encodes safety (\textquotedblleft no silent success\textquotedblright) and liveness (\textquotedblleft bounded improvement or fail-safe halt\textquotedblright) as explicit runtime conditions.

\subsection{Context and Memory}
State carries context usage and quality signals (window used/max, a simple quality score, segmented context) as well as working/external memory and memory checkpoints. These fields feed PRP decisions and provide the substrate for replay and post-hoc analysis of context drift.

\subsection{Exhaustion Signals}
Exhaustion is tracked explicitly: \texttt{exhaustion\_mode} (typed enum), an optional probability, and a recovery log. These signals inform guards on PRP edges (e.g., blocking \texttt{conclude}/\texttt{test} paths under certain modes) and provide operator telemetry for false-stop detection and mitigation.

\subsection{Refinement Ledger}
Every cycle appends a \texttt{RefinementLedgerEntry} (hypothesis, status/outcome, exhaustion trigger, test results, novelty metadata, causal links, optional success prediction). Ingestion normalizes payloads and maintains chronological order. The ledger underpins reproducibility and is the canonical artifact for audits and learning-based extensions.

\subsection{Workspace Snapshots}
On important events (e..g., HumanClone rejection), the runtime captures a workspace snapshot and adds it to the incident bundle. This allows operators to reconstruct file-system state alongside ledger/replay data during diagnosis.

\subsection{Deterministic Replay and CLI}
A \texttt{TimeTravelRecorder} writes append-only JSONL entries (stage transitions, tool calls, state snapshots) with thread/cycle metadata. CLI tools provide replay (filter by cycle) and diff (compare cycles on tokens, tool calls, stage counts, status). The format is line-oriented, lock-protected, and suitable for standard UNIX tooling.

\subsection{Orchestrator Graph and Prompts}
The orchestrator is a LangGraph app constructed via the shared \texttt{build\_graph}. In autonomous mode, its system prompt instantiates the inner $\text{Evaluate} \to \text{Critique} \to \text{Plan} \to \text{Execute}$ loop and a Finalization Protocol that requires \texttt{request\_final\_review}. A dedicated HumanClone system prompt specifies persona and the structured trigger output, ensuring reliable gate enforcement.

\subsection{Worker Agents}
The agent package is intentionally minimal: a straightforward profile and graph, a simple system prompt, and no meta-level planning. The orchestrator handles \textit{what}/\textit{why}; agents handle \textit{how}. This keeps execution components light and replaceable.

\subsection{Agent Registry and Residency (“Hotpath”)}
A FastAPI Agent Registry (SQLite-backed) provides registration and health heartbeats. The schema includes a persistent \texttt{hotpath} flag; operations preserve \texttt{hotpath} status on upsert and expose queries for \texttt{hotpath}-only views. Residency is enforced by the agent management tool: delete operations consult the registry and block removal when \texttt{hotpath=1}, guaranteeing residency across long runs.

\subsection{Agent Lifecycle Tools}
The \texttt{agent\_management} tool wraps shell scripts (\texttt{spawn-agent.sh}, \texttt{delete-agent.sh}) to manage Dockerized agents from within the orchestrator loop. This is the concrete mechanism behind the \textquotedblleft dynamic fleet\textquotedblright\ design and is where residency checks are enforced on deletion.

\textit{Implementation summary.} Today’s codebase implements: (i) a guarded PRP state machine with an inescapable skeptical gate, (ii) a durable refinement ledger and deterministic replay with CLI tooling, and (iii) service residency enforced at both registry and tooling layers. These pieces elevate \textquotedblleft reflect, persist, verify\textquotedblright\ from prompt heuristics to runtime guarantees, providing a practical foundation for exhaustion-resistant autonomy.


\section{Evaluation}
\label{sec:evaluation}
We evaluate Quadracode on two compact stress tests that target the failure modes it is designed to address: premature halts and fault recovery in long-running workflows. The goal is to demonstrate that making skepticism, persistence, and replay protocol-level invariants yields practical reliability gains with tractable overhead. We keep this section concise and reproducible; extended plots, prompts, and logs belong in the appendix and artifact bundle.

\subsection{Experimental Questions and Setup}

\paragraph{Questions.}
\begin{enumerate}
    \item[Q1] (\textbf{False-stops}): Does protocol-level skeptical gating reduce premature terminations on multi-step tasks?
    \item[Q2] (\textbf{Recovery}): Do residency and deterministic replay improve recovery time and completion rate under injected faults?
    \item[Q3] (\textbf{Overhead}): What latency/cost overheads do gating, residency, and replay introduce?
    \item[Q4] (\textbf{Traceability}): Does the refinement ledger + replay produce complete, auditable incident bundles?
\end{enumerate}

\paragraph{Environment.}
Frontier-class chat/completion model (fixed temperature and decoding parameters), single node with stable network, Redis Streams for the event fabric. We run $N$ episodes per task per configuration ($\ge 3$ seeds), randomizing task instances and seed assignment. Budgets: tokens, wall-clock, and iteration count as specified in \S 4.

\paragraph{Systems compared.}
\begin{itemize}
    \item \textbf{Ours:} Quadracode (skeptical gate + PRP + residency + deterministic replay).
    \item \textbf{B1 (baseline):} A contemporary multi-agent framework (e.g., \cite{Wu2023}) configured as a manager–worker with a reviewer/critic and otherwise comparable tool access and prompting.
\end{itemize}
Unless noted, both systems use the same model, tools, and tasks.

\subsection{Tasks}
\paragraph{Task A — Premature-halt resistance.}
A multi-step workflow in which naïve agents frequently \textquotedblleft consider done\textquotedblright\ too early (e.g., multi-file change + verification + integration step, or multi-stage data cleanup with a required final validation). Success requires producing the final artifact and passing a task-specific verification script. False-stop is registered when a system proposes completion that fails verification (a failure mode common in complex benchmarks like \cite{Mialon2023}).

\paragraph{Task B — Failure-recovery liveness.}
A long-running workflow with fault injection at a deterministic point (e.g., worker crash or short fabric outage). Success requires completing the task without manual intervention after fault injection. We measure time-to-recovery (first successful post-fault verification) and escalation rate (fail-safe halts).

\subsection{Metrics}
\begin{itemize}
    \item \textbf{Success rate (\%).} Episodes that complete within budget and pass verification.
    \item \textbf{False-stop rate (\%).} Fraction of episodes in which a \textquotedblleft done\textquotedblright\ proposal fails verification.
    \item \textbf{Iterations to acceptance.} PRP cycles until final acceptance.
    \item \textbf{Tokens / wall-clock.} Total tokens (prompt+completion) and end-to-end time.
    \item \textbf{Recovery time (Task B).} Time from fault injection to first verified completion.
    \item \textbf{Escalation rate (Task B).} Episodes that end in fail-safe halt.
    \item \textbf{Incident bundle completeness.} Presence and integrity of (i) refinement ledger entries, (ii) replay trace, and (iii) workspace snapshot.
\end{itemize}

\paragraph{Statistical reporting.}
Report mean and 95\% bootstrap CIs across episodes; where paired comparisons are appropriate, include a nonparametric paired test. Per-task seeds and instance lists are included in the artifact bundle.

\subsection{Results}
\paragraph{Task A (False-stops).}
Table 1 summarizes success and false-stop rates. Quadracode reduces false-stops relative to B1 and increases end-to-end success with modest additional iterations. The ablation in \S 6.5 attributes most of the gain to the skeptical gate; residency reduces variance (fewer cold restarts), while replay does not materially affect success but improves traceability (Table 3).

\paragraph{Task B (Recovery).}
Figure 3 plots recovery time distributions under injected faults. With residency + replay enabled, the orchestrator resumes from a warm state and reconstructs causal context, yielding shorter recovery and fewer escalations. Without these mechanisms, more episodes exhaust budget and trigger fail-safe halts (higher escalation rate).

\paragraph{Overhead.}
Figure 4 shows latency and token overheads. Skeptical gating introduces predictable extra turns; residency adds negligible steady-state latency but avoids cold-start spikes; replay adds constant logging overhead. We discuss cost/performance trade-offs in \S 8.

\paragraph{Traceability.}
Across both tasks, incident bundles contain complete ledgers and replay traces. Replay reproduces stage transitions and tool invocations deterministically; diffs between cycles identify the action that converted a failing hypothesis into a passing one.

\subsection{Ablations (Protocol Switches)}
We toggle the protocol mechanisms to isolate their effects:
\begin{itemize}
    \item \textbf{Gate off (no HumanClone).} Increases false-stops and lowers success (Task A); slightly faster but less reliable runs.
    \item \textbf{Lenient vs. strict PRP thresholds.} Lenient thresholds reduce iterations but admit more borderline completions; strict thresholds reduce false-stops at the cost of additional cycles.
    \item \textbf{Residency off.} Higher variance and longer tails in time-to-complete (Task A) and recovery time (Task B) due to cold restarts.
    \item \textbf{Replay off.} Similar success when no faults occur; degraded diagnosis and higher operator time during incidents; incident bundle incomplete.
\end{itemize}

\paragraph{Presentation.}
\begin{itemize}
    \item Table 2: Ablation matrix (gate/residency/replay/thresholds $\times$ success, false-stops, iterations, tokens, time).
    \item Figure 5: Cost–success Pareto (tokens vs. success) across ablations to visualize trade-offs.
\end{itemize}

\subsection{Reproducibility}
We release: (i) \texttt{/experiments/run\_task\_A.sh} and \texttt{/experiments/run\_task\_B.sh} to generate all results; (ii) configuration files for budgets, thresholds, and residency flags; (iii) per-episode seeds and task manifests; and (iv) raw refinement ledgers and replay traces. Figures and tables in this section can be regenerated with a single command; checksums of regenerated artifacts are included in \texttt{RESULTS.md}.

\subsection{Limitations of This Evaluation}
Our study is intentionally compact: two stress tests, one model family, and a single contemporary framework baseline. Broader generalization (more domains, multi-tenant throughput, public long-horizon benchmarks) and learned reviewers are left to future work (\S 9).


\section{Operator Experience \& Auditability}
\label{sec:operator_experience}
Quadracode is designed to be operated like a production system rather than \textquotedblleft babysat\textquotedblright\ like a demo agent. This section describes how an operator observes progress, responds to issues, and reconstructs causality. The guiding principle is explainable autonomy: every state change is logged, every acceptance is challenged, and every halt produces an auditable bundle that enables rapid diagnosis and reproducible reruns.

\subsection{Run Walkthrough (Operator’s View)}
\begin{itemize}
    \item \textbf{Initialization.} An operator submits a task specification and budget (iterations, tokens/cost, wall-clock). The orchestrator initializes the PRP state, allocates a worker set (respecting hotpath residency), and creates the first refinement ledger entry (hypothesis, planned steps, initial context).
    \item \textbf{Cycle execution.} Each inner-loop cycle---$\text{Evaluate} \to \text{Critique} \to \text{Plan} \to \text{Execute}$---appends a ledger entry with (i) artifacts produced, (ii) tool calls and outcomes, (iii) updated context usage/quality, and (iv) the current exhaustion mode if any. Operators see cumulative budgets and liveness indicators (cycles completed, improvement signals, pending gate status).
    \item \textbf{Skeptical gating.} When the orchestrator proposes \textquotedblleft done,\textquotedblright\ the HumanClone reviewer issues a structured trigger. If the evidence is inadequate, the trigger records the rationale and required artifacts; the PRP transitions back to \texttt{HYPOTHESIZE}. From the operator’s perspective, this appears as a short \textquotedblleft challenge $\to$ refine\textquotedblright\ segment in the ledger rather than an ambiguous near-finish stall. Only a post-action challenge can lead to acceptance.
    \item \textbf{Normal completion.} On acceptance, the final ledger entry captures (i) acceptance rationale, (ii) verification results, (iii) summary of deltas from the last rejected proposal, and (iv) a compact roll-up of costs/latency. Operators can export this entry as the canonical trace for downstream systems.
    \item \textbf{Fail-safe halt.} If improvement stalls or a hard budget is reached, the run terminates in a fail-safe halt with operator escalation. Instead of a quiet timeout, the operator receives a structured incident bundle (below), enabling a focused follow-up rather than guesswork.
\end{itemize}

\subsection{Incident Bundle (On Escalation)}
When a run halts safely, Quadracode emits a single, self-contained package with:
\begin{itemize}
    \item \textbf{Refinement ledger (JSONL).} Ordered, append-only records of PRP stages, gate interactions, tool calls, and metrics; includes pointers to artifacts and context snapshots.
    \item \textbf{Time-travel replay trace.} Deterministic, line-oriented log of stage transitions and tool invocations sufficient to reconstruct control flow; includes cycle/thread identifiers for partial replay.
    \item \textbf{Workspace snapshot.} Filesystem manifest and checksums (plus optional tarball) for key working directories at the point of halt or gate rejection.
    \item \textbf{Budget \& telemetry summary.} Final counters for iterations, tokens/cost, wall-clock, failure codes, and any invariant violations encountered.
    \item \textbf{Gate rationale digest.} The last HumanClone trigger with structured reasons for rejection and any required evidence not yet satisfied.
    \item \textbf{Reproduction script.} A minimal command or config set to re-execute the final $N$ cycles locally or in CI for debugging.
\end{itemize}
The bundle is designed for two uses: rapid triage (operator opens the digest and gate rationale first) and forensic replay (engineer replays cycles to isolate the causal step that transitions a failing hypothesis into a passing one).

\subsection{Replay and Diff (Causal Reconstruction)}
Quadracode’s deterministic replay allows operators to reproduce a run’s control flow without contacting external services beyond what is necessary for artifact inspection. Typical operations are:
\begin{itemize}
    \item \textbf{Single-cycle replay.} Reconstruct the state and messages for cycle $k$ to verify a tool-induced failure or confirm that a fix would have unblocked progress.
    \item \textbf{Segment replay.} Reproduce cycles $k \dots k+m$ to study a refinement streak (e.g., after a gate rejection) and verify that the proposed plan change led to acceptance.
    \item \textbf{Diff between cycles.} Compute a structured diff ($k$ vs. $k+1$ or \textquotedblleft last reject\textquotedblright\ vs. \textquotedblleft final accept\textquotedblright), summarizing: stage counts, tool call set and statuses, artifacts added/removed/modified, context usage, and any exhaustion-mode transitions.
    \item \textbf{Invariant audit.} Validate that \textquotedblleft post-action challenge,\textquotedblright\ \textquotedblleft test-after-rejection,\textquotedblright\ and \textquotedblleft context-update per cycle\textquotedblright\ rules were satisfied; violations are highlighted with direct links into the ledger.
\end{itemize}
In practice, this replay/diff workflow shortens incident resolution: operators quickly localize where progress stalled (e.g., a missing integration step, a flaky tool, or an overly lenient threshold) and either adjust configuration (thresholds, budgets, residency) or open a targeted issue with the exact reproduction steps.

\textit{Takeaway.} From start to finish, the operator experience emphasizes observability over intuition. The skeptical gate prevents silent success; the PRP ledger and deterministic replay make progress and backtracking explicit; and the escalation bundle turns ambiguous timeouts into reproducible incidents. Together, these features enable teams to run long-horizon autonomy with the same operational discipline expected of production services.


\section{Interoperability, Security, and Reliability}
\label{sec:interop_security_reliability}
Quadracode is engineered to behave like a production system: components communicate over a stable contract, safety checks are enforced by code (not convention), and operators can reconstruct causality after the fact. This section summarizes how the implementation supports interop, security-by-construction, and reliability/fault tolerance, with pointers to the concrete mechanisms already in the codebase.

\subsection{Interoperability \& Extensibility}
\begin{itemize}
    \item \textbf{Message contract and fabric.} All inter-component traffic flows through a canonical \texttt{MessageEnvelope} schema (timestamp, sender, recipient, message, payload) and standard mailbox keys (\texttt{qc:mailbox/<recipient>}). The Redis Streams adapter (\texttt{RedisMCPMessaging}) wraps \texttt{xadd}/\texttt{xrange}/\texttt{xdel} as tool calls, exposing messaging behind an MCP-style abstraction; this decouples Quadracode from a single backend and enables testing/mocking without touching call sites. Poison-pill handling preserves malformed payloads in a \texttt{\_raw} field to avoid crashes.
    \item \textbf{Durable, append-only log semantics.} Redis Streams provide an append-only substrate; entries persist until explicitly deleted, giving the runtime an audit trail \textquotedblleft for free.\textquotedblright
    \item \textbf{Service APIs and contracts.} The Agent Registry is a FastAPI service with typed request/response models (registration, heartbeat, listing) and a \texttt{hotpath} flag surfaced at the API layer, so other systems can discover and respect residency. Query filters support \texttt{healthy-only} and \texttt{hotpath-only} views for orchestration and tooling.
    \item \textbf{Lifecycle tooling as adapters.} The \texttt{agent\_management} tool is a thin Python wrapper around shell scripts (\texttt{spawn-agent.sh}, \texttt{delete-agent.sh}), letting the orchestrator manage Dockerized agents from within the same tool-calling loop---no bespoke integration code required.
\end{itemize}
\textit{Implication.} The combination of a strict envelope, append-only fabric, typed service contracts, and tool adapters makes it straightforward to swap backends, stub services, or integrate with external control planes while preserving on-wire compatibility.

\subsection{Security \& Isolation (v1 posture)}
\begin{itemize}
    \item \textbf{Typed validation on critical paths.} The \texttt{MessageEnvelope} and \texttt{HumanCloneTrigger} are Pydantic models; malformed messages are quarantined instead of crashing the orchestrator (envelope \texttt{\_raw}), and HumanClone triggers must conform to a fenced-JSON schema with enumerated fields. This reduces injection/format risks and ensures the skeptical gate is driven by structured data, not prompts.
    \item \textbf{Skeptical reviewer constraints.} The HumanClone is stateless, defaults to rejection, and is forbidden from using escalation tools; its only role is to challenge \textquotedblleft done\textquotedblright\ with a structured rationale and required artifacts. This narrows its authority and limits blast radius.
    \item \textbf{Workspace integrity hooks.} On gate rejection, the runtime captures a workspace snapshot alongside the ledger entry, enabling post-hoc inspection of files/artifacts without giving reviewers write power over the workspace.
    \item \textbf{Residency as a policy barrier.} The registry enforces a \texttt{hotpath} residency bit; deletion is blocked for \texttt{hotpath} agents unless explicitly forced. This prevents accidental teardown of critical services and keeps long-lived context warm.
    \item \textbf{Scope note.} v1 does not include sandboxing or authn/z; message/schema validation and residency checks are the primary defenses. These are sufficient for single-tenant deployments and CI, and provide clear extension points for hardening (auth headers, signed envelopes, tool allowlists) to defend against known tool-use vulnerabilities \cite{Deng2024}.
\end{itemize}

\subsection{Reliability \& Fault Tolerance}
\begin{itemize}
    \item \textbf{At-least-once delivery and idempotent handlers.} The Redis Streams design plus envelope parsing gives the runtime at-least-once semantics; parser errors are handled defensively, returning empty batches rather than crashing, and message handlers are written to be idempotent at the state-machine boundary.
    \item \textbf{Guarded protocol transitions.} The PRP is a finite-state machine with guarded edges (e.g., \texttt{requires\_human\_clone}, \texttt{allow\_if\_exhaustion\_in}/\texttt{block\_if\_exhaustion\_in}). Illegal transitions raise typed errors; gate-driven rejections force a reset to \texttt{HYPOTHESIZE}. This enforces safety/liveness at code level.
    \item \textbf{Deterministic replay.} A \texttt{TimeTravelRecorder} writes append-only JSONL events (stage transitions, tool calls, snapshots) with cycle/thread metadata; a CLI supports replay and diff for cycle-granular forensics. Locks guard concurrent writes; retention is bounded in-memory and unbounded on disk.
    \item \textbf{Refinement ledger as causal substrate.} Each cycle appends a typed \texttt{RefinementLedgerEntry} (hypothesis, status/outcome, exhaustion trigger, novelty/causal metadata), providing a structured backbone for audits, ablations, and simple learning hooks (e.g., success prediction).
    \item \textbf{Health and residency checks.} The registry records heartbeats and exposes \texttt{hotpath-only} filters; the lifecycle tool consults the registry before destructive actions, preventing reliability regressions due to external autoscaling or operator error.
    \item \textbf{Budget-bounded halts with escalation.} When improvement stalls or a hard limit is hit, runs terminate in a fail-safe halt and emit an incident bundle (ledger + replay + snapshot), supporting rapid recovery rather than silent failure. (See \S 7 for operator workflow.)
\end{itemize}

\subsection{Reliability/Interop Limitations (and upgrade path)}
\begin{itemize}
    \item Authn/z and multi-tenant isolation are not part of v1; the envelope/registry contracts provide insertion points for JWT-style headers and per-tenant namespaces.
    \item Backend portability is mediated by tools; swapping Redis is feasible via the MCP adapter, but requires adapter parity for publish/read/delete.
    \item Backpressure and QoS policies are basic; future work can add rate-aware readers and stream trimming strategies driven by budget and priority.
\end{itemize}
\textit{Takeaway.} Quadracode’s on-wire stability (envelopes), typed contracts (Pydantic models), ledger + replay, and residency enforcement together provide interoperable, auditable, and fault-tolerant behavior suitable for long-running autonomy---without sacrificing extensibility for future hardening or alternative backends.


\section{Limitations \& Future Work}
\label{sec:limitations_future_work}
Quadracode targets reliability for long-horizon autonomy by enforcing protocol-level skepticism, persistence, and replay. In its current form, the system is practical for single-tenant deployments and compact stress tests, but several aspects remain limited. We outline the most salient constraints and a prioritized roadmap.

\subsection{Current Limitations}
\paragraph{Methodological}
\begin{itemize}
    \item \textbf{No learned verifier/RL (v1).} The HumanClone reviewer is stateless and rule-driven (a pattern similar to \cite{Zheng2023}); PRP thresholds are hand-tuned. This simplifies control but may be conservative or inefficient in edge cases.
    \item \textbf{Success verification is task-specific.} Validation scripts are external to the protocol. When verifiers are weak or missing, the skeptical gate can only enforce process discipline, not ground-truth correctness.
    \item \textbf{Context quality signals are coarse.} The current \textquotedblleft context usage/quality\textquotedblright\ metrics and the simple exhaustion predictor (v1) provide heuristics, not calibrated estimates of reasoning degradation.
\end{itemize}

\paragraph{Systems}
\begin{itemize}
    \item \textbf{Single-tenant posture.} The runtime assumes a trusted operator and tooling; there is no multi-tenant isolation, authn/z, or quota enforcement per tenant.
    \item \textbf{Backend reliance.} The event fabric targets Redis Streams; swapping backends requires adapter parity and careful testing of delivery semantics and retention policies.
    \item \textbf{Replay boundaries.} Deterministic replay reconstructs control flow and serialized state, but cannot reproduce external side-effects that are not snapshotted (e.g., networked tools with nondeterministic data).
    \item \textbf{Residency vs. resource use.} Hotpath agents improve liveness but reserve resources; misconfiguration can increase steady-state cost without proportional gains.
    \item \textbf{Log/ledger growth.} Long runs generate large append-only traces; storage growth and log rotation/compaction policies are basic.
    \item \textbf{Fault injection coverage.} Evaluation uses targeted faults (agent crash, brief fabric outage). Broader chaos scenarios (network partitions, slow drains, clock skew) are not yet exercised.
\end{itemize}

\paragraph{Security/Compliance}
\begin{itemize}
    \item \textbf{Minimal hardening.} There is no sandboxing, capability enforcement, or signed envelopes. The message schema and registry checks reduce some risks but do not prevent malicious tools or prompt-level injection.
    \item \textbf{Data governance.} Workspace snapshots may contain sensitive artifacts; redaction and retention controls are limited.
\end{itemize}

\subsection{Future Work (Prioritized Roadmap)}
\paragraph{Near-term (protocol and ops)}
\begin{enumerate}
    \item \textbf{Learned reviewer plug-in.} Replace or augment HumanClone with a process-reward model / critic (e.g., \cite{Lightman2023}) that learns acceptance criteria from the refinement ledger, while preserving the hard skeptical gate as a fallback.
    \item \textbf{Adaptive thresholds \& budgets.} Make PRP thresholds and iteration/cost budgets policy-driven (learned per task class), with guardrails to avoid oscillation.
    \item \textbf{Replay completeness.} Snapshot external tool inputs/outputs and introduce effect journals so replay can reconstruct side-effects or stub them deterministically.
    \item \textbf{Storage hygiene.} Add compaction/roll-up for ledgers and traces (e.g., checkpoint+delta) and retention policies per project/run.
    \item \textbf{Operator UX.} Ship opinionated dashboards for incident bundles, replay/diff navigation, and invariant violation highlighting.
\end{enumerate}

\paragraph{Mid-term (scale and hardening)}
\begin{enumerate}
    \setcounter{enumi}{5} % Continue numbering
    \item \textbf{Multi-tenant isolation and authn/z.} Namespaced mailboxes, signed \texttt{MessageEnvelopes}, per-tenant quotas, and scoped tool allowlists; audit trails for compliance.
    \item \textbf{QoS and backpressure.} Priority queues, rate-aware consumers, and budget-aware scheduling to maintain SLAs under load.
    \item \textbf{Backend portability.} Mature the messaging adapter to support pluggable fabrics (e.g., NATS/Kafka) with formal tests for at-least-once semantics and ordering guarantees.
    \item \textbf{Chaos engineering.} Periodic fault campaigns (network partitions, slow consumers, clock skew, stream trimming) with SLOs for recovery and bounded escalation.
\end{enumerate}

\paragraph{Long-term (learning and generalization)}
\begin{enumerate}
    \setcounter{enumi}{9} % Continue numbering
    \item \textbf{End-to-end learning loops.} Integrate RL or bandit strategies for planner choices, tool selection, and gate aggressiveness, using ledger/replay as the experience buffer.
    \item \textbf{Richer benchmarks.} Expand beyond the two stress tests to public long-horizon suites (e.g., \cite{Mialon2023}, \cite{AgentBench2023}) and report cross-domain generalization.
    \item \textbf{Formal properties.} Specify and verify safety (\textquotedblleft post-action challenge\textquotedblright) and liveness (bounded-improvement termination) with machine-checked proofs; expose proofs as executable invariants.
    \item \textbf{Cost governance.} Policy modules for per-run/per-tenant cost ceilings, along with Pareto tuning of gate strictness vs. tokens/latency.
\end{enumerate}

\textit{Summary.} The present system elevates reflect-persist-verify from prompt heuristics to runtime guarantees, yielding practical gains in false-stop resistance, recovery, and auditability. The next steps focus on (i) learned reviewers and adaptive policies to reduce conservatism, (ii) scale and hardening for multi-tenant operation, and (iii) broader evaluations and formalization to establish generality and guarantees. These extensions preserve Quadracode’s core thesis---skepticism and persistence as protocol invariants---while expanding its applicability to larger, noisier, and more demanding deployments.


\section{Reproducibility \& Artifact Availability}
\label{sec:reproducibility}
We release a self-contained artifact that rebuilds all tables/figures and reproduces the two stress tests with the exact protocol switches reported in \S 6. The package includes code, configs, seeds, task manifests \& verifiers, PRP ledgers, time-travel traces, and scripts to regenerate results.

\subsection{Code, Versioning, and Layout}
\begin{itemize}
    \item \textbf{Repository \& tag.} Public repo with a frozen release tag for this paper; we include the commit hash in the camera-ready.
    \item \textbf{Layout (top-level).}
    \begin{quote}
        \texttt{/src/} \hspace{1em}\# runtime, orchestrator, agents, registry, recorder \\
        \texttt{/configs/} \hspace{1em}\# YAMLs for budgets, PRP thresholds, residency flags, model params \\
        \texttt{/tasks/} \hspace{1em}\# task specs, instance lists, and verification scripts for A/B \\
        \texttt{/experiments/} \hspace{1em}\# run scripts and pipelines to reproduce \S 6 \\
        \texttt{/artifacts/} \hspace{1em}\# ledgers/, replay/, snapshots/ (populated by runs) \\
        \texttt{/plots/} \hspace{1em}\# generated tables/figures (auto-filled by scripts) \\
        \texttt{/RESULTS.md} \hspace{1em}\# checksums + quick summary of reproduced metrics
    \end{quote}
    \item \textbf{Prompts \& protocol.} HumanClone and orchestrator prompts, PRP default transition graph, and invariant checks are included under \texttt{/src} so protocol behavior is auditable.
\end{itemize}

\subsection{Environment: Deterministic Setup}
\begin{itemize}
    \item \textbf{Containerized option (recommended).} A pinned Docker image (Python, OS, Redis version) and \texttt{docker-compose} file to launch the Redis Streams fabric.
    \item \textbf{Local option.} \texttt{environment.yml} (or \texttt{requirements.txt}) plus a small \texttt{post\_install.sh} that fetches model/tool stubs for offline replay.
    \item \textbf{Version pins.} We fix major packages (HTTP clients, Pydantic, Redis client) and log versions at runtime into the ledger header.
\end{itemize}

\subsection{Tasks, Seeds, and Verification}
\begin{itemize}
    \item \textbf{Tasks A/B.} Each task directory contains: (i) a machine-readable task definition, (ii) an instance list with per-instance seed, and (iii) a verification script (exit code + message).
    \item \textbf{Seeds.} A single \texttt{seeds.txt} file per task; the run scripts read \texttt{--seeds} to ensure episode parity.
    \item \textbf{Budgets.} Tokens, wall-clock, and iteration caps live in \texttt{/configs/*}; the exact configs used for the paper are tagged and copied into \texttt{artifacts/configs\_used/} on each run.
\end{itemize}

\subsection{One-Command Reproduction}
\paragraph{Task A (false-stop resistance).}
\begin{quote}
    \texttt{./experiments/run\_task\_A.sh \textbackslash} \\
    \texttt{\ \ \ \ --config configs/task\_a\_strict.yaml \textbackslash} \\
    \texttt{\ \ \ \ --seeds tasks/A/seeds.txt \textbackslash} \\
    \texttt{\ \ \ \ --out artifacts/A}
\end{quote}

\paragraph{Task B (fault injection \& recovery).}
\begin{quote}
    \texttt{./experiments/run\_task\_B.sh \textbackslash} \\
    \texttt{\ \ \ \ --config configs/task\_b\_recovery.yaml \textbackslash} \\
    \texttt{\ \ \ \ --fault-spec tasks/B/faults.yaml \textbackslash} \\
    \texttt{\ \ \ \ --seeds tasks/B/seeds.txt \textbackslash} \\
    \texttt{\ \ \ \ --out artifacts/B}
\end{quote}

\paragraph{Tables \& figures.}
\begin{quote}
    \texttt{python experiments/make\_tables.py --artifacts artifacts/ --out plots/} \\
    \texttt{python experiments/make\_figures.py --artifacts artifacts/ --out plots/}
\end{quote}
All scripts return non-zero on failure and emit a short summary to \texttt{RESULTS.md}. The plotting scripts read only ledger/traces/metrics---no ad-hoc log scraping.

\subsection{Determinism, Caching, and Replay}
\begin{itemize}
    \item \textbf{Randomness.} We fix RNG seeds for orchestration choices and sampling params; model APIs remain inherently stochastic, which is reflected in confidence intervals.
    \item \textbf{Caching.} Tool responses that are pure functions are cached (hash-keyed) to reduce variance across reruns.
    \item \textbf{Replay fidelity.} For incident analysis and exact reproduction of control flow, we rely on the time-travel recorder and workspace snapshots. The \texttt{qc-replay} CLI reconstructs stage transitions and tool calls; \texttt{qc-diff} compares cycles or segments (e.g., \textquotedblleft last rejection\textquotedblright\ vs. \textquotedblleft final acceptance\textquotedblright). External non-deterministic side effects (e.g., network tools) are stubbed or journaled when feasible.
\end{itemize}

\subsection{Artifact Integrity and Checks}
\begin{itemize}
    \item \textbf{Checksums.} Every generated table/figure has a SHA-256 recorded in \texttt{RESULTS.md}; the script re-computes and flags mismatches.
    \item \textbf{Schema validation.} Ledgers and traces are validated against typed schemas before plot generation; invalid entries abort the build with a clear error.
    \item \textbf{Budget provenance.} Final tokens/time/iterations are exported per run and cross-checked against config caps.
\end{itemize}

\subsection{Licensing, Privacy, and Redaction}
\begin{itemize}
    \item \textbf{Licenses.} Source code under a permissive license; third-party models/tools follow their respective licenses (listed in \texttt{LICENSES.md}).
    \item \textbf{Privacy.} Workspace snapshots may contain generated artifacts; we provide a redaction list and default filters that remove secrets/PII patterns from bundles.
    \item \textbf{Responsible use.} Verification scripts avoid contacting external services unless explicitly enabled.
\end{itemize}

\subsection{Long-Term Archival}
We will publish the exact release tarball (code + configs + seeds) and a frozen artifact bundle (minimal ledgers/traces to regenerate tables/figures) to an archival service and reference the DOI in the camera-ready.

\textit{Reproducibility guarantee.} With the containerized setup, a single machine and the commands above regenerate the numerical results and plots in \S 6. Any deviation (package/version drift, failed schema validation, checksum mismatch) is surfaced in \texttt{RESULTS.md} and the CI log, enabling co-authors and readers to verify the claims without manual tuning.


\section{Conclusion}
\label{sec:conclusion}
We presented Quadracode, a systems runtime for long-horizon agents that turns prompt-level heuristics into protocol invariants. A mandatory skeptical gate (HumanClone), the Perpetual Refinement Protocol with a checkpointed ledger, service-residency (``hotpath'') controls, and deterministic replay collectively enforce ``keep going,'' prevent silent success, and make runs auditable.

In compact stress tests, protocol-level skepticism reduced premature halts, while residency and replay improved recovery under injected faults with modest overhead. Beyond headline metrics, the operator experience is practical: progress is visible in the ledger, decisions are traceable via replay/diff, and failures surface as structured incident bundles.

Limitations include single-tenant posture, task-specific verifiers, and hand-tuned thresholds. Future work will integrate learned reviewers, adaptive policies and budgets, broader long-horizon benchmarks, multi-tenant hardening, and formal safety/liveness properties. Overall, Quadracode offers a concrete foundation for exhaustion-resistant autonomous systems.


\newpage
\begin{thebibliography}{15}

\bibitem{AgentBench2023}
Liu, Y., et al. (2023).
\textit{AgentBench: Evaluating LLMs as Agents}.
arXiv preprint arXiv:2308.03688.

\bibitem{Deng2024}
Deng, G., et al. (2024).
\textit{Security and Privacy in Tool-using Large Language Model Agents}.
arXiv preprint arXiv:2405.02928.

\bibitem{Huang2023}
Huang, J., et al. (2023).
\textit{Large Language Models Cannot Self-Correct Reasoning Yet}.
arXiv preprint arXiv:2310.01798.

\bibitem{Lightman2023}
Lightman, T., et al. (2023).
\textit{Let's Verify Step by Step}.
arXiv preprint arXiv:2305.20050.

\bibitem{Liu2023}
Liu, N. F., et al. (2023).
\textit{Lost in the Middle: How Language Models Use Long Contexts}.
arXiv preprint arXiv:2307.03172.

\bibitem{Madaan2023}
Madaan, A., et al. (2023).
\textit{Self-Refine: Iterative Refinement with Self-Feedback}.
arXiv preprint arXiv:2303.17651.

\bibitem{Mialon2023}
Mialon, G., et al. (2023).
\textit{GAIA: A Benchmark for General AI Assistants}.
arXiv preprint arXiv:2311.12983.

\bibitem{Shinn2023}
Shinn, N., Labash, B., \& Gopinath, A. (2023).
\textit{Reflexion: Language Agents with Verbal Reinforcement Learning}.
arXiv preprint arXiv:2303.11366.

\bibitem{Sreekanti2022}
Sreekanti, V., et al. (2022).
\textit{Banyan: A Stateful Serverless Platform}.
In 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22).

\bibitem{Wang2023}
Wang, L., et al. (2023).
\textit{A Survey of Large Language Model based Autonomous Agents}.
arXiv preprint arXiv:2308.11430.

\bibitem{Wu2023}
Wu, Q., et al. (2023).
\textit{AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation}.
arXiv preprint arXiv:2308.08155.

\bibitem{Xi2023}
Xi, Z., et al. (2023).
\textit{The Rise and Potential of Large Language Model Based Agents: A Survey}.
arXiv preprint arXiv:2309.07864.

\bibitem{Yao2023}
Yao, S., et al. (2023).
\textit{Tree of Thoughts: Deliberate Problem Solving with Large Language Models}.
arXiv preprint arXiv:2305.10601.

\bibitem{Yin2024}
Yin, S., et al. (2024).
\textit{AgentDebugger: An In-context Debugging and Replay System for LLM Agents}.
arXiv preprint arXiv:2402.04609.

\bibitem{Zheng2023}
Zheng, L., et al. (2023).
\textit{Judging LLM-as-a-judge with MT-Bench and Chatbot Arena}.
arXiv preprint arXiv:2306.05685.

\end{thebibliography}

\end{document}